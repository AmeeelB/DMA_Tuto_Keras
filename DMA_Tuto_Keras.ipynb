{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Bienvenue dans le **Tuto Keras** !\n",
        "\n",
        "A travers **5 parties** vous aurez l'occasion de parcourir et de découvrir quelques outils très utiles disponible grâce au **framework Keras**.\n",
        "\n",
        "Chaque partie du tutoriel est divisée en sous-parties **\"Cours\"** et **\"Exercice\"** :\n",
        "\n",
        "**Parties \"Cours\"** : Elles présentent les concepts et les codes fondamentaux pour construire un modèle de reconnaissance de chiffres. **Attention**, ces codes ne sont pas toujours complets et nécessitent des adaptations pour fonctionner.\n",
        "\n",
        "**Parties \"Exercice\"** : Elles vous mettent au défi d'appliquer les concepts appris en complétant ou modifiant les codes du cours. C'est en réalisant ces exercices que vous comprendrez et maîtriserez réellement les techniques.\n",
        "\n",
        "L'objectif principal de ce tutoriel est de vous faire **apprendre par la pratique**. Si les codes du cours étaient complets et exécutables tels quels, vous seriez tenté de les copier-coller sans véritablement les comprendre.\n",
        "\n",
        "Les parties \"Exercice\" vous incitent à :\n",
        "\n",
        "- Réfléchir aux concepts présentés dans le cours.\n",
        "- Chercher les informations nécessaires pour compléter les codes.\n",
        "- Expérimenter différentes solutions et paramètres.\n",
        "\n",
        "N'hésitez pas à vous référer aux parties \"Cours\" pour trouver des indications et des exemples de code. Mais gardez à l'esprit que vous devrez les adapter pour répondre aux exigences des exercices.\n",
        "\n",
        "Nous allons pouvoir commencer avec la première partie, **bon apprentissage** !"
      ],
      "metadata": {
        "id": "HFUt7vv6RaD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 1 : Importation de Keras et du dataset\n",
        "\n",
        "## 1.1 Importations des packages pour Keras"
      ],
      "metadata": {
        "id": "Qkn7BFLzNRug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9GbJ9gfNLMA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Nous importons tensorflow pour utiliser le framework qui nous intéresse : Keras\n",
        "\n",
        "-> tensorflow est ce qu'on appelle une API, elle nous permet de créer des modèles de réseaux de neurones\n",
        "\n",
        "(2) Depuis tensorflow.keras on importe datasets, layers, et models\n",
        "\n",
        "-> datasets : fournit une collection de datasets\n",
        "-> layers : permet de construire un réseau de neurones couche par couche\n",
        "-> models : pour construire, compiler et entraîner un modèle de réseau de neurones\n",
        "\n",
        "(3) numpy est importé pour la manipulation des matrices\n",
        "\n",
        "(4) matplotlib.pyplot nous permet de visualiser les images"
      ],
      "metadata": {
        "id": "yxEkQoThNe9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Importation du dataset et normalisation"
      ],
      "metadata": {
        "id": "YwOrk16hfXw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "# Normalisation\n",
        "train_images, test_images = train_images / val_norm, test_images / val_norm"
      ],
      "metadata": {
        "id": "4mqV3dBfNtJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) La fonction datasets.mnist.load_data() charge le dataset MNIST qui est divisé en deux ensembles : un ensemble d’entraînement (60 000 images) et un ensemble de test (10 000 images)\n",
        "-> Le dataset MNIST contient des images de chiffres manuscrits (de 0 à 9), utilisées couramment pour tester des modèles d'apprentissage supervisé. Chaque image mesure 28x28 pixels et est en nuances de gris.\n",
        "\n",
        "(1) train_images et test_images contiennent les images (28x28 pixels) des chiffres écrits à la main\n",
        "\n",
        "(1) train_labels et test_labels contiennent les étiquettes associées aux images (les chiffres réels que les images représentent)\n",
        "\n",
        "(2) Les images sont initialement dans une plage de valeurs entre 0 et 255. Pour faciliter l'entraînement du modèle, nous normaliserons les valeurs des pixels. Cela est illustrer dans le code par la division par val_norm. On veut que cela transforme les valeurs dans un intervalle de [0 ; 1], pour aider à la convergence du modèle."
      ],
      "metadata": {
        "id": "zG44y3pBNXEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice 1 :\n",
        "\n",
        "Dans cette partie exercice vous serez mis à l'épreuve afin de produire votre propre code sur votre ordinateur.\n",
        "\n",
        "## 1.1 Exercice : Importation des packages pour Keras\n",
        "\n",
        "En reprenant le code dans la partie cours (1.1 Importation des packages pour Keras), importer les packages utiles pour l'utilisation de Keras."
      ],
      "metadata": {
        "id": "Da2wW134N-1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** : A quoi nous sert les modules importer depuis tensorfow.keras ? **Relier** les modules avec leurs fonctions :\n",
        "\n",
        "A. datasets •      • 1. construire, compiler et entraîner un modèle de réseau de neurones\n",
        "\n",
        "B. layers   •      • 2. fournit une collection de datasets\n",
        "\n",
        "C. models   •      • 3. construire un réseau de neurones couche par couche"
      ],
      "metadata": {
        "id": "qFVs_4BeOB3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Exercice : Importation du dataset et normalisation\n",
        "\n",
        "Sur votre ordinateur personnel, reprendre le code de la partie cours (1.2 Importation du dataset et normalisation). Définir la valeur de val_norm afin de normaliser nos données."
      ],
      "metadata": {
        "id": "96Xl7wqcOO01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 2 : Le modèle\n",
        "\n",
        "## 2.1 Initialisation du modèle"
      ],
      "metadata": {
        "id": "0C2KsCvBPY7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(nbr_cc, activation='activation_function'),\n",
        "    layers.Dense(nbr_cs, activation='activation_function')\n",
        "])"
      ],
      "metadata": {
        "id": "2mzan0tDPbrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Sequential : Crée un modèle linéaire empilant les couches les unes après les autres.\n",
        "\n",
        "(2) Ajout d'une couche\n",
        "-> Elle transforme une image 28x28 en un vecteur de 784 valeurs (28 * 28).\n",
        "-> Permet de passer d'une image 2D à une liste de valeurs pour le réseau de neurones.\n",
        "\n",
        "(3) nbr_cc = nombre de neuronnes dans la couche cachée\n",
        "\n",
        "(3) activation='activation_function' : Choix de la fonction d'activation ( ReLU, sigmoïde, ...)\n",
        "\n",
        "(4) nbr_cs = nombre de neuronnes dans la couche de sortie"
      ],
      "metadata": {
        "id": "WqCQra8dPep9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Compilation"
      ],
      "metadata": {
        "id": "8L6frHmsPh_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='optimizer',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H3XdH7cePi3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) optimizer='optimizer' : Algorithme d'optimisation\n",
        "\n",
        "(2) loss='sparse_categorical_crossentropy' : Fonction de perte adaptée à la classification multi-classes avec des labels sous forme d'entiers.\n",
        "\n",
        "(3) metrics=['accuracy'] : Mesure la performance du modèle en termes de précision."
      ],
      "metadata": {
        "id": "BD92fT4mPnv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice 2 : Le modèle\n",
        "\n",
        "## 2.1 Exercice : Initialisation du modèle\n",
        "\n",
        "En reprenant le code dans la partie cours (2.1 Initialisation du modèle) :\n",
        "\n",
        "- On fixera d'abord le nombre de neuronnes par couche caché de 128 et le nombre de neuronnes pour la couche de sortie de 10 car 10 est le nombre de classes (0 à 9 pour le dataset MNIST).\n",
        "\n",
        "- Puis on choisira pour les couches cachées, la fonction d'activation 'relu' (ReLU : Rectified Linear Unit) qui permet d'introduire la non-linéarité. Nous ne metterons aucune fonction d'activation pour la couche de sortie car le résultat brut est traité par la fonction de perte."
      ],
      "metadata": {
        "id": "f_rIC-EHPqtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Exercice : Compilation\n",
        "\n",
        "Reprendre le code dans la partie cours (2.2 Compilation), on choisira l'algorithme d'optimisation 'adam', basé sur la descente de gradient adaptative."
      ],
      "metadata": {
        "id": "y0V8Q62wPs_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 3 : Entraînement et Évaluation\n",
        "\n",
        "## 3.1 Entraînement"
      ],
      "metadata": {
        "id": "y8YVPMJsPwyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=nbr_epochs)"
      ],
      "metadata": {
        "id": "BmmbHqPwP5F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) epochs=nbr_epochs : le nombre de fois que le modèle parcourt l'ensemble du jeu de données"
      ],
      "metadata": {
        "id": "UmwHqwvlP72D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Évaluation"
      ],
      "metadata": {
        "id": "3CCGMrs8QDoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "Pppeo_4lQGNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle est testé sur des données jamais vues pour mesurer sa performance.\n",
        "\n",
        "test_loss : la valeur de la fonction de perte (loss) sur les données de test, c'est une mesure de l’erreur moyenne\n",
        "\n",
        "test_acc : la précision du modèle, c’est-à-dire la proportion de bonnes réponses\n",
        "\n",
        "On observe généralement que test_acc < train_acc mais si test_acc est largement inférieur à train_acc alors on est probablement en situation de surapprentissage.\n",
        "\n",
        "Dans l'idéal on souhaiterait un test_acc qui tend vers 1 et un test_loss bas."
      ],
      "metadata": {
        "id": "C-yHtaACQJFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice 3 :\n",
        "\n",
        "## 3.1 Exercice : Entraînement\n",
        "\n",
        "Essayer le code de la partie cours (3.1 Entraînement) avec un nombre fixé d'epochs = 5"
      ],
      "metadata": {
        "id": "WZQIl1RXQSLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Exercice : Évaluation\n",
        "\n",
        "Reprendre le code de la partie cours (3.2 Évaluation) et déterminer le cas dans lequel nous sommes :\n",
        "\n",
        "- Situation de surapprentissage\n",
        "- Situation normale\n",
        "- Situation de très bonne précision du modèle"
      ],
      "metadata": {
        "id": "7np9YscqQWet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 4 : Réseau de Neuronnes CNN\n",
        "\n",
        "Après avoir compris le fonctionnement d’un modèle dense simple sur MNIST, nous allons maintenant construire un **modèle CNN** (Convolutional Neural Network) plus adapté à l’analyse d’images. Les CNN sont capables de **détecter automatiquement** des motifs visuels utiles (bords, textures, formes...) dans les images, sans qu’on ait besoin de les décrire à la main.\n",
        "\n",
        "Ce que tu vas apprendre dans cette partie :\n",
        "\n",
        "- Créer un CNN avec **Conv2D et MaxPooling2D**.\n",
        "\n",
        "- Comprendre comment chaque couche transforme les images.\n",
        "\n",
        "- Utiliser un **outil interactif** (ipywidgets) pour tester différents paramètres du modèle sans modifier le code manuellement.\n",
        "\n",
        "- **Évaluer** visuellement les **performances** du réseau après entraînement.\n",
        "\n",
        "- **Tester** une **image aléatoire** du jeu de test et afficher la **prédiction du modèle**."
      ],
      "metadata": {
        "id": "-i3fxU77QXnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Prétraitement des données\n",
        "\n",
        "Dans le réseau de neuronnes précédent, les images étaient traitées comme des vecteurs de taille 784 (car 28×28 = 784).\n",
        "Mais dans un réseau convolutionnel (CNN), les couches Conv2D attendent des images à 3 dimensions"
      ],
      "metadata": {
        "id": "Gw4K6Y_gQajz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "9os8QCXYQdf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Le modèle CNN"
      ],
      "metadata": {
        "id": "CvejFwZJQgaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(filters_1, filters_2, filters_3, epochs):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(filters_1, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(filters_2, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(filters_3, (3, 3), activation='relu'),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    history = model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "\n",
        "    plt.plot(history.history['accuracy'], label='accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UK6cq7B1QkoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction create_model initialise, compile, entraîne et teste un réseau de neurones convolutif (CNN) à 3 couches Conv2D, en utilisant les paramètres fournis par l'utilisateur :\n",
        "\n",
        "- filters_1 : nombre de filtre dans la 1ere couche convolutive\n",
        "- filters_2 : nombre de filtre dans la 2eme couche convolutive\n",
        "- filters_3 : nombre de filtre dans la 3eme couche convolutive\n",
        "- epochs : Nombre d’époques (itérations) pour entraîner le modèle\n",
        "\n",
        "\n",
        "L'initialisation du modèle s'effectue presque de la même manière que précédemment, on ajoutera cependant 3 couches convolutive (Conv2D) et 2 couches de MaxPooling pour réduire la taille de l’image.\n",
        "\n",
        "La compilation, l'entraînement et la phase d'évaluation sont identiques."
      ],
      "metadata": {
        "id": "5BoK8R0wQlpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Prédiction"
      ],
      "metadata": {
        "id": "YJvdnyqzQuOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model):\n",
        "\n",
        "    random_index = np.random.randint(0, test_images.shape[0])\n",
        "    image = test_images[random_index]\n",
        "    label = test_labels[random_index]\n",
        "\n",
        "\n",
        "    plt.imshow(image.reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.title(f\"Vrai label: {label}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    image = image.reshape((1, 28, 28, 1))\n",
        "    prediction = model.predict(image)\n",
        "    predicted_label = tf.argmax(prediction, axis=1).numpy()[0]\n",
        "\n",
        "    print(f\"Prédiction : {predicted_label}\")"
      ],
      "metadata": {
        "id": "NiJPfv-jQwOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction a pour objectif de tester un modèle entraîné en affichant une image de test choisie aléatoirement et en comparant la prédiction du modèle avec le vrai label. C’est une mise en pratique directe pour vérifier visuellement les performances du réseau.\n",
        "\n",
        "(2) np.random.randint(...) tire un indice au hasard dans le dataset de test.\n",
        "\n",
        "(3) image : récupère l’image\n",
        "\n",
        "(4) label : récupère le vrai label correspondant à l'image.\n",
        "\n",
        "(5) plt.imshow : redimensionne l’image pour l’afficher en 2D (28x28).\n",
        "\n",
        "(8) Le modèle retourne un vecteur de scores (logits) pour les 10 classes (chiffres de 0 à 9).\n",
        "\n",
        "(9) tf.argmax(..., axis=1) : donne l’indice (la classe) avec le plus grand score.\n",
        "\n",
        "(9) .numpy()[0] : transforme le résultat TensorFlow en entier Python.\n",
        "\n",
        "(10) Affiche la classe prédite par le réseau dans la console"
      ],
      "metadata": {
        "id": "rYWF2mRAQy4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice 4 : Le modèle CNN\n",
        "\n",
        "Après avoir copié puis collé l'ensemble des codes de la partie 4 nous serons en mesure de mettre en place une interface interactive pour tester facilement des combinaisons d’hyperparamètres et comprendre visuellement leur impact.\n",
        "\n",
        "Autrement dit, cela permettra de tester différentes architectures de CNN (en modifiant le nombre de filtres) et différentes durées d'entraînement, de façon très simple, sans écrire une ligne de plus."
      ],
      "metadata": {
        "id": "fXUrUcJnQ5aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact"
      ],
      "metadata": {
        "id": "RSFKUcI5Q8X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters_1 = widgets.IntSlider(value=32, min=16, max=64, step=16, description='Filters (Conv1):')\n",
        "filters_2 = widgets.IntSlider(value=64, min=32, max=128, step=32, description='Filters (Conv2):')\n",
        "filters_3 = widgets.IntSlider(value=64, min=32, max=128, step=32, description='Filters (Conv3):')\n",
        "epochs = widgets.IntSlider(value=5, min=1, max=20, step=1, description='Epochs:')\n",
        "\n",
        "\n",
        "interact(create_model, filters_1=filters_1, filters_2=filters_2, filters_3=filters_3, epochs=epochs)"
      ],
      "metadata": {
        "id": "rQJO6WTRQ9DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quels sont les paramètres qui ont offert la meilleure performance à ton modèle ?\n",
        "\n",
        "Reprends le code ci-dessous pour faire la partie prédiction, en remplaçant val_filtre1 val_filtre2 et val_filtre3 ainsi que val_epochs par les valeurs trouvées."
      ],
      "metadata": {
        "id": "umPzJgv2RCJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_perf():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(val_filtre1, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(val_filtre2, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(val_filtre3, (3, 3), activation='relu'),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_images, train_labels, epochs=val_epochs, validation_data=(test_images, test_labels))\n",
        "\n",
        "    return model\n",
        "\n",
        "predict_image(model)"
      ],
      "metadata": {
        "id": "Xx_MlqSKRD3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie 5 : Utilisation de VGG16 avec MNIST\n",
        "\n",
        "VGG16 est un **réseau convolutif profond**, pré-entraîné sur le dataset **ImageNet** (1,2M images, 1000 classes).\n",
        "Il est très utilisé pour le **transfert learning**, qui consiste à réutiliser ce qu’il a appris pour d'autres tâches. Même si MNIST est simple, c’est un bon exercice pour **comprendre comment adapter un modèle existant** à un autre type de données.\n"
      ],
      "metadata": {
        "id": "XupC7hdEUFhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Nouvelles importation de packages"
      ],
      "metadata": {
        "id": "ZmBegulyVDy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "zsggDdOhVHPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) VGG16 : Import du modèle VGG16 pré-entraîné\n",
        "\n",
        "(2) image : Pour manipuler les images (resize, conversion)\n",
        "\n",
        "(3) preprocess_input : Prétraitement des images pour VGG16"
      ],
      "metadata": {
        "id": "7yXrtDM9VKie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Réduction du jeu de données"
      ],
      "metadata": {
        "id": "mFLaNaKlWJ2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images[:500]\n",
        "train_labels = train_labels[:500]\n",
        "test_images = test_images[:100]\n",
        "test_labels = test_labels[:100]"
      ],
      "metadata": {
        "id": "K3KMCqy7WEL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, nous nous limiterons volontairement à un petit sous-ensemble pour gagner du temps et économiser de la mémoire."
      ],
      "metadata": {
        "id": "72jXR86EVqSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Conversion en RGB"
      ],
      "metadata": {
        "id": "VyCIgUQdWR-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_rgb = np.stack([np.stack([img]*3, axis=-1) for img in train_images])\n",
        "test_images_rgb = np.stack([np.stack([img]*3, axis=-1) for img in test_images])"
      ],
      "metadata": {
        "id": "64oOfDBDWVV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- VGG16 attend des images avec 3 canaux (rouge, vert, bleu).\n",
        "- On duplique le canal des niveaux de gris pour créer une image RGB artificielle."
      ],
      "metadata": {
        "id": "JS0_5dHZWZbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Redimensionnement des images"
      ],
      "metadata": {
        "id": "CH7it5d1WkDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_resized = np.array([image.array_to_img(img).resize((224, 224)) for img in train_images_rgb])\n",
        "test_images_resized = np.array([image.array_to_img(img).resize((224, 224)) for img in test_images_rgb])"
      ],
      "metadata": {
        "id": "8oXXs5MNWZCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- On redimensionne chaque image à l'aide de la fonction `resize` car VGG16 attend des images de 224x224 pixels."
      ],
      "metadata": {
        "id": "gtyJZoNqW4EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Conversion en tableaux NumPy"
      ],
      "metadata": {
        "id": "yay3c9RxXPiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_resized = np.stack([np.array(img) for img in train_images_resized])\n",
        "test_images_resized = np.stack([np.array(img) for img in test_images_resized])"
      ],
      "metadata": {
        "id": "3AmVcksoW3tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On convertit les images PIL en tableaux numériques (`np.array`) pour qu’ils soient utilisables dans le modèle."
      ],
      "metadata": {
        "id": "t0pFEqPNXgAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 Prétraitement pour VGG16"
      ],
      "metadata": {
        "id": "w7RgLG1oXgoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_resized = preprocess_input(train_images_resized)\n",
        "test_images_resized = preprocess_input(test_images_resized)"
      ],
      "metadata": {
        "id": "_4Mq3YuWXqu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Le modèle VGG16 attend des images normalisées selon les statistiques du dataset ImageNet.\n",
        "- Cette fonction fait le bon prétraitement automatique."
      ],
      "metadata": {
        "id": "TgfmnAyWXtWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.7 Chargement de VGG16 sans la dernière couche"
      ],
      "metadata": {
        "id": "6KX-5baQXttF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "1TlagdteX-OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `weights='imagenet'` → On utilise les poids appris sur ImageNet.\n",
        "- `include_top=False` → On enlève la dernière couche de classification pour mettre la nôtre."
      ],
      "metadata": {
        "id": "BNmOd-5HX8aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.8 Défiger certaines couches (fine-tuning)"
      ],
      "metadata": {
        "id": "4V3-lwHdYNn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.trainable = True\n",
        "for layer in vgg16_model.layers[:10]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "DtYSWo2FYPZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- On rend les couches entraînables, sauf les 10 premières.\n",
        "- Cela permet de réadapter VGG16 à notre tâche sans tout casser."
      ],
      "metadata": {
        "id": "3arXGtm_YSJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.9 Construction du modèle final"
      ],
      "metadata": {
        "id": "USIS6IxvYYAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    vgg16_model,                        # Base du modèle pré-entraîné\n",
        "    layers.Flatten(),                  # Aplatit les sorties du bloc convolutif\n",
        "    layers.BatchNormalization(),       # Normalise les activations pour stabiliser l'entraînement\n",
        "    layers.Dense(64, activation='relu'),  # Couche dense classique avec ReLU\n",
        "    layers.Dense(10, activation='softmax')  # Couche de sortie (10 classes MNIST)\n",
        "])\n",
        "\n",
        "##  11. Compilation du modèle\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "##  12. Entraînement du modèle\n",
        "\n",
        "\n",
        "history = model.fit(train_images_resized, train_labels, epochs=5,\n",
        "                    validation_data=(test_images_resized, test_labels))"
      ],
      "metadata": {
        "id": "00aO_8J_YcBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.10 Évaluation et visualisation"
      ],
      "metadata": {
        "id": "10mNQyjVYtmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images_resized, test_labels, verbose=2)\n",
        "print(f\"\\n✅ Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "2BZVRIUpY20z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Évalue les performances du modèle sur des données **jamais vues**."
      ],
      "metadata": {
        "id": "_RfbMIXUY3lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Accuracy (train)')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy (val)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Courbe de précision - VGG16 fine-tuné sur MNIST')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SEezGnMtY6QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affiche les courbes d'entraînement et de validation pour suivre l'apprentissage."
      ],
      "metadata": {
        "id": "wgDi2nUmZG5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice 5\n",
        "\n",
        "La particularité de la partie 5 est qu'elle n'est pas revenue sur les notions déjà vu précédement. Ainsi dans cet exercice nous vous mettons au défis de mettre en pratique toutes les connaissances acquises jusqu'à maintenant pour construire, à l'aide de VGG16, un modèle de classification d'images MNIST.\n",
        "\n",
        "1) Importer les bibliothèques\n",
        "\n",
        "- tensorflow, keras, numpy, matplotlib.pyplot,\n",
        "- les modules spécifiques à VGG16 (VGG16, preprocess_input, image)\n",
        "\n",
        "2) Chargement et prétraitement des données MNIST\n",
        "\n",
        "- Charger MNIST\n",
        "- Réduire les données\n",
        "- Convertir les images en RGB\n",
        "- Redimensionner les images pour VGG16\n",
        "- Prétraiter les images\n",
        "\n",
        "3) Construction du modèle\n",
        "\n",
        "4) Compilation du modèle\n",
        "\n",
        "5) Entraînement du modèle\n",
        "\n",
        "6) Évaluation et visualisation\n",
        "\n"
      ],
      "metadata": {
        "id": "SRgb3PxQgfKX"
      }
    }
  ]
}